{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:06:50.759369Z",
     "start_time": "2020-11-17T19:06:45.056008Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# our nice list of imports is in here\n",
    "#i hate this, but the notebook won't recognize our custom modules w/o it\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import lib\n",
    "from lib import utils\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import urllib\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-17T22:00:36.009Z"
    }
   },
   "outputs": [],
   "source": [
    "def extr_pmask(pred, face):\n",
    "    \"\"\"\n",
    "        @param pred is a prediction from our project model\n",
    "        @param face is a face object returned from the MTCNN detector\n",
    "        @return results after non-standard regularization\n",
    "    \"\"\"\n",
    "    p_mask = pred[0][1]\n",
    "    p_nomask = pred[0][0]\n",
    "    p_face = f['confidence']\n",
    "    p_noface = 1 - p_face\n",
    "    \n",
    "    results = [\n",
    "        (p_face * p_nomask) / p_face,\n",
    "        (p_noface * p_mask) / p_face\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:25:22.550045Z",
     "start_time": "2020-11-17T21:25:21.606646Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_model = load_model('../models/kaggle_relu_softmax_1e31e5')\n",
    "presentation_model = load_model('../models/mnm/presentation/presentation.checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using The Model With Video Feed\n",
    "\n",
    "+ We have two available facial detection algorithms: \n",
    "  1. Haar Cascade - faster detection, but only tuned for full, frontal views of faces.\n",
    "  2. MTCNN - slower detection, but returns extra features and can detect faces from a variety of angles -- not only the front.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T21:30:46.659608Z",
     "start_time": "2020-11-17T21:28:24.308475Z"
    }
   },
   "outputs": [],
   "source": [
    "# use haar cascade to detect faces (frontal)\n",
    "# HC_FRONTAL_FACE = os.path.join(HC_DATA_DIR, \n",
    "#                                'haarcascade_frontalface_default.xml')\n",
    "# classifier = cv2.CascadeClassifier(HC_FRONTAL_FACE)\n",
    "\n",
    "\n",
    "# use MTCNN to detect faces\n",
    "classifier = MTCNN()\n",
    "\n",
    "\n",
    "labels_dict={ 0:'No Mask', 1:'Mask' }\n",
    "color_dict={ 0: (0,0,255), 1: (0,255,0) }\n",
    "\n",
    "size = 8\n",
    "\n",
    "# open webcam feed\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# alternatively, open feed from a file\n",
    "cap = cv2.VideoCapture('../memask4.mov')\n",
    "\n",
    "# EVEN from a mobile device (UNTESTED)\n",
    "# cap = cv.VideoCapture(1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        # frame = cv2.flip(frame, 1, 1) # flip so view looks more natural live (?)\n",
    "        \n",
    "\n",
    "        # detection is a little faster on smaller images -- so let's make it small\n",
    "        small = cv2.resize(frame, (frame.shape[1] // size, frame.shape[0] // size))\n",
    "\n",
    "        # detect faces with haar cascades\n",
    "        # faces = classifier.detectMultiScale(small)\n",
    "        \n",
    "        # detect faces with MTCNN\n",
    "        faces = classifier.detect_faces(small)\n",
    "\n",
    "        for f in faces:\n",
    "            # reverse the scale-down of the frame for bounding box (haar)\n",
    "#             (x, y, w, h) = [v * size for vstack in f] \n",
    "#             keypoints = None\n",
    "            \n",
    "            # reverse the scale-down of the frame for bounding box (MTCNN)\n",
    "            (x, y, w, h) = [v * size for v in f['box']]\n",
    "            keypoints = f['keypoints']\n",
    "            p_face = f['confidence']\n",
    "            p_noface = 1 - p_face\n",
    "                \n",
    "        \n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            resized = cv2.resize(face, (50,50))\n",
    "            normalized = resized/255.0\n",
    "            \n",
    "            reshaped = np.reshape(normalized,(-1,50,50,1))\n",
    "            reshaped = np.vstack([reshaped])\n",
    "            result1 = kaggle_model.predict(reshaped)\n",
    "            \n",
    "            reshaped2 = np.reshape(normalized, (-1, 50, 50, 3))\n",
    "            reshaped2 = np.vstack([reshaped2])\n",
    "            result2 = presentation_model.predict(reshaped2)\n",
    "            result2[0][0] = (p_face * result2[0][0]) / p_face\n",
    "            result2[0][1] = (p_noface * result2[0][1]) / p_face\n",
    "            \n",
    "            # print(result1)\n",
    "            # print(result2)\n",
    "            \n",
    "            \n",
    "            left = frame\n",
    "            right = np.copy(frame)\n",
    "            frames = [left, right]\n",
    "\n",
    "            label1 = np.argmax(result1, axis=1)[0]\n",
    "            label2 = np.argmax(result2, axis=1)[0]\n",
    "            # print(\"Kaggle Prediction: {}\\nPresentation Prediction: {}\".format(labels_dict[label1], labels_dict[label2]))\n",
    "\n",
    "            cv2.rectangle(left, (x,y), (x+w,y+h), color_dict[label1], 2)\n",
    "            cv2.rectangle(left, (x,y-40), (x+w,y), color_dict[label1], -1)\n",
    "            cv2.putText(\n",
    "                left, \n",
    "                labels_dict[label1], \n",
    "                (x+5, y-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (255,255,255),\n",
    "                2\n",
    "            )\n",
    "            cv2.rectangle(left, (x, y+h), (x+w,y+h+40), color_dict[label1], -1)\n",
    "            cv2.putText(\n",
    "                left,\n",
    "                \"Top Ranked Kaggle Model\",\n",
    "                (x+5, y+h+20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                2\n",
    "            )\n",
    "            \n",
    "            cv2.rectangle(right, (x,y), (x+w,y+h), color_dict[label2], 2)\n",
    "            cv2.rectangle(right, (x,y-40), (x+w,y), color_dict[label2], -1)\n",
    "            cv2.putText(\n",
    "                right, \n",
    "                labels_dict[label2], \n",
    "                (x+5, y-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (255,255,255),\n",
    "                2\n",
    "            )\n",
    "            cv2.rectangle(right, (x, y+h), (x+w,y+h+40), color_dict[label2], -1)\n",
    "            cv2.putText(\n",
    "                right,\n",
    "                \"Our Model\",\n",
    "                (x+65, y+h+20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                2\n",
    "            )\n",
    "            \n",
    "            # extra fun when using MTCNN :)\n",
    "            for frame in frames:\n",
    "                if keypoints is not None:\n",
    "                    cv2.circle(\n",
    "                        frame, \n",
    "                        (tuple([k * size for k in keypoints['left_eye']])), \n",
    "                        2, (255,0,255), 2\n",
    "                    )\n",
    "                    cv2.circle(\n",
    "                        frame, \n",
    "                        (tuple([k * size for k in keypoints['right_eye']])), \n",
    "                        2, (255,0,255), 2\n",
    "                    )\n",
    "                    cv2.circle(\n",
    "                        frame, \n",
    "                        (tuple([k * size for k in keypoints['nose']])), \n",
    "                        2, (255,0,255), 2\n",
    "                    )\n",
    "                    cv2.circle(\n",
    "                        frame, \n",
    "                        (tuple([k * size for k in keypoints['mouth_left']])), \n",
    "                        2, (255,0,255), 2\n",
    "                    )\n",
    "                    cv2.circle(\n",
    "                        frame, \n",
    "                        (tuple([k * size for k in keypoints['mouth_right']])), \n",
    "                        2, (255,0,255), 2)\n",
    "            # end of extra fun with MTCNN\n",
    "\n",
    "            \n",
    "        view = np.hstack(frames)\n",
    "        cv2.imshow('LIVE DETECTION ACTIVE', view)\n",
    "        key = cv2.waitKey(10)\n",
    "\n",
    "        if key == 27: # if Esc key pressed -- end feed\n",
    "            break\n",
    "        \n",
    "#         clear_output(wait=True)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T19:34:36.735045Z",
     "start_time": "2020-11-17T19:34:36.619711Z"
    }
   },
   "outputs": [],
   "source": [
    "# stop video\n",
    "cap.release()\n",
    "\n",
    "# close windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "563.736px",
    "left": "1135.07px",
    "right": "20px",
    "top": "77.9858px",
    "width": "442.983px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
