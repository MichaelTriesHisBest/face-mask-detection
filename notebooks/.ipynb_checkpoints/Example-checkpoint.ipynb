{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face mask detection\n",
    "\n",
    "Here I am going to detect whether a person is wearing mask or not. I am focussing on only two classes that are 'face_with_mask' and face_no_mask'.\n",
    "\n",
    "## Source Page\n",
    "+ ["
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\n",
    "annotations=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\")\n",
    "train=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\n",
    "submission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are having 6024 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=os.listdir(images)\n",
    "b=os.listdir(annotations)\n",
    "a.sort()\n",
    "b.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(b),len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=a[1698:]\n",
    "test_images=a[:1698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imread(os.path.join(images,test_images[0]))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imread(os.path.join(images,train_images[1]))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options=['face_with_mask','face_no_mask']\n",
    "train= train[train['classname'].isin(options)]\n",
    "train.sort_values('name',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=[]\n",
    "for i in range(len(train)):\n",
    "    arr=[]\n",
    "    for j in train.iloc[i][[\"x1\",'x2','y1','y2']]:\n",
    "        arr.append(j)\n",
    "    bbox.append(arr)\n",
    "train[\"bbox\"]=bbox  \n",
    "def get_boxes(id):\n",
    "    boxes=[]\n",
    "    for i in train[train[\"name\"]==str(id)][\"bbox\"]:\n",
    "        boxes.append(i)\n",
    "    return boxes\n",
    "print(get_boxes(train_images[3]))\n",
    "image=train_images[3]\n",
    "\n",
    "img=plt.imread(os.path.join(images,image))\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "boxes=get_boxes(image)\n",
    "for box in boxes:\n",
    "    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=train_images[5]\n",
    "\n",
    "img=plt.imread(os.path.join(images,image))\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "boxes=get_boxes(image)\n",
    "for box in boxes:\n",
    "    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['face_with_mask','face_no_mask'],train.classname.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=50\n",
    "data=[]\n",
    "path='/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'\n",
    "def create_data():\n",
    "       for i in range(len(train)):\n",
    "            arr=[]\n",
    "            for j in train.iloc[i]:\n",
    "                   arr.append(j)\n",
    "            img_array=cv2.imread(os.path.join(images,arr[0]),cv2.IMREAD_GRAYSCALE)\n",
    "            crop_image = img_array[arr[2]:arr[4],arr[1]:arr[3]]\n",
    "            new_img_array=cv2.resize(crop_image,(img_size,img_size))\n",
    "            data.append([new_img_array,arr[5]])\n",
    "create_data()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]\n",
    "plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl=LabelEncoder()\n",
    "y=lbl.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x).reshape(-1,50,50,1)\n",
    "x=tf.keras.utils.normalize(x,axis=1)\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "model=Sequential()\n",
    "model.add(Conv2D(100,(3,3),input_shape=x.shape[1:],activation='relu',strides=2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "model.fit(x,y,epochs=30,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=MTCNN()\n",
    "img=plt.imread(os.path.join(images,test_images[0]))\n",
    "face=detector.detect_faces(img)\n",
    "for face in face:\n",
    "        bounding_box=face['box']\n",
    "        x=cv2.rectangle(img,\n",
    "              (bounding_box[0], bounding_box[1]),\n",
    "              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "              (0,155,255),\n",
    "              10)\n",
    "        plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imread(os.path.join(images,test_images[3]))\n",
    "face=detector.detect_faces(img)\n",
    "for face in face:\n",
    "        bounding_box=face['box']\n",
    "        x=cv2.rectangle(img,\n",
    "              (bounding_box[0], bounding_box[1]),\n",
    "              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "              (0,155,255),\n",
    "              10)\n",
    "        plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=MTCNN()\n",
    "test_df=[]\n",
    "for image in test_images:\n",
    "    img=plt.imread(os.path.join(images,image))\n",
    "    faces=detector.detect_faces(img)\n",
    "    test=[]\n",
    "    for face in faces:\n",
    "        bounding_box=face['box']\n",
    "        test.append([image,bounding_box])\n",
    "    test_df.append(test)\n",
    "test=[]\n",
    "for i in test_df:\n",
    "    if len(i)>0:\n",
    "        if len(i)==1:\n",
    "            test.append(i[0])\n",
    "        else:\n",
    "            for j in i:\n",
    "                test.append(j)  \n",
    "sub=[]\n",
    "rest_image=[]\n",
    "for i in test:\n",
    "    sub.append(i[0])\n",
    "for image in test_images:\n",
    "    if image not in sub:\n",
    "        rest_image.append(image) \n",
    "detector=MTCNN()\n",
    "test_df_=[]\n",
    "for image in rest_image:\n",
    "    img=cv2.imread(os.path.join(images,image))\n",
    "    faces=detector.detect_faces(img)\n",
    "    test_=[]\n",
    "    for face in faces:\n",
    "        bounding_box=face['box']\n",
    "        test_.append([image,bounding_box])\n",
    "    test_df_.append(test_) \n",
    "for i in test_df_:\n",
    "    if len(i)>0:\n",
    "        if len(i)==1:\n",
    "            test.append(i[0])\n",
    "        else:\n",
    "            for j in i:\n",
    "                test.append(j)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative=[]\n",
    "for i in test:\n",
    "    for j in i[1]:\n",
    "        if j<0:\n",
    "            negative.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "def create_test_data():\n",
    "            for j in test:\n",
    "                if j not in negative:\n",
    "                    img=cv2.imread(os.path.join(images,j[0]),cv2.IMREAD_GRAYSCALE)\n",
    "                    img=img[j[1][1]:j[1][1]+j[1][3],j[1][0]:j[1][0]+j[1][2]]\n",
    "                    new_img=cv2.resize(img,(50,50))\n",
    "                    new_img=new_img.reshape(-1,50,50,1)\n",
    "                    predict=model.predict(new_img)\n",
    "                    test_data.append([j,predict])\n",
    "\n",
    "create_test_data()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=[]\n",
    "classname=[]\n",
    "for i,j in test_data:\n",
    "    classname.append(np.argmax(j))\n",
    "    image.append(i)\n",
    "df=pd.DataFrame(columns=['image','classname'])\n",
    "df['image']=image\n",
    "df['classname']=classname\n",
    "df['classname']=lbl.inverse_transform(df['classname'])\n",
    "image=[]\n",
    "x1=[]\n",
    "x2=[]\n",
    "y1=[]\n",
    "y2=[]\n",
    "for i in df['image']:\n",
    "    image.append(i[0])\n",
    "    x1.append(i[1][0])\n",
    "    x2.append(i[1][1])\n",
    "    y1.append(i[1][2])\n",
    "    y2.append(i[1][3])\n",
    "df['name']=image\n",
    "df['x1']=x1\n",
    "df['x2']=x2\n",
    "df['y1']=y1\n",
    "df['y2']=y2    \n",
    "df.drop(['image'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('name',axis=0,inplace=True,ascending=False)\n",
    "df.to_csv('submission_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
