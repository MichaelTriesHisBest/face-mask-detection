{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face mask detection\n",
    "\n",
    "Here I am going to detect whether a person is wearing mask or not. I am focussing on only two classes that are 'face_with_mask' and face_no_mask'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\n",
    "# annotations=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\")\n",
    "# train=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\n",
    "# submission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))\n",
    "notebook_dir = !pwd\n",
    "notebook_dir = notebook_dir[0]\n",
    "root_dir = os.path.abspath(os.path.join(notebook_dir, os.pardir))\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "images = os.path.join(data_dir, 'images')\n",
    "annotations = os.path.join(data_dir, 'annotations')\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "submission = pd.read_csv(os.path.join(data_dir, 'submission.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15412\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>69</td>\n",
       "      <td>126</td>\n",
       "      <td>294</td>\n",
       "      <td>392</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>505</td>\n",
       "      <td>10</td>\n",
       "      <td>723</td>\n",
       "      <td>283</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>75</td>\n",
       "      <td>252</td>\n",
       "      <td>264</td>\n",
       "      <td>390</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>521</td>\n",
       "      <td>136</td>\n",
       "      <td>711</td>\n",
       "      <td>277</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6098.jpg</td>\n",
       "      <td>360</td>\n",
       "      <td>85</td>\n",
       "      <td>728</td>\n",
       "      <td>653</td>\n",
       "      <td>face_no_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   x1   x2   y1   y2       classname\n",
       "0  2756.png   69  126  294  392  face_with_mask\n",
       "1  2756.png  505   10  723  283  face_with_mask\n",
       "2  2756.png   75  252  264  390   mask_colorful\n",
       "3  2756.png  521  136  711  277   mask_colorful\n",
       "4  6098.jpg  360   85  728  653    face_no_mask"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1799.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1799.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  x1  x2  y1  y2  classname\n",
       "0  1800.jpg NaN NaN NaN NaN        NaN\n",
       "1  1800.jpg NaN NaN NaN NaN        NaN\n",
       "2  1800.jpg NaN NaN NaN NaN        NaN\n",
       "3  1799.jpg NaN NaN NaN NaN        NaN\n",
       "4  1799.jpg NaN NaN NaN NaN        NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are having 6024 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_formats = ['jpg', 'jpeg', 'png']\n",
    "a = [img for img in a if img.split(\".\")[-1] in image_formats]\n",
    "b=os.listdir(annotations)\n",
    "a.sort()\n",
    "b.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4326 0\n"
     ]
    }
   ],
   "source": [
    "print(len(b),len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=a[1698:]\n",
    "test_images=a[:1698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-34c132b188e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-716c9b3a2345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img=plt.imread(os.path.join(images,test_images[0]))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c0806ea4c301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img=plt.imread(os.path.join(images,train_images[1]))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options=['face_with_mask','face_no_mask']\n",
    "train= train[train['classname'].isin(options)]\n",
    "train.sort_values('name',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=[]\n",
    "for i in range(len(train)):\n",
    "    arr=[]\n",
    "    for j in train.iloc[i][[\"x1\",'x2','y1','y2']]:\n",
    "        arr.append(j)\n",
    "    bbox.append(arr)\n",
    "train[\"bbox\"]=bbox  \n",
    "def get_boxes(id):\n",
    "    boxes=[]\n",
    "    for i in train[train[\"name\"]==str(id)][\"bbox\"]:\n",
    "        boxes.append(i)\n",
    "    return boxes\n",
    "print(get_boxes(train_images[3]))\n",
    "image=train_images[3]\n",
    "\n",
    "img=plt.imread(os.path.join(images,image))\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "boxes=get_boxes(image)\n",
    "for box in boxes:\n",
    "    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=train_images[5]\n",
    "\n",
    "img=plt.imread(os.path.join(images,image))\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "boxes=get_boxes(image)\n",
    "for box in boxes:\n",
    "    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['face_with_mask','face_no_mask'],train.classname.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=50\n",
    "data=[]\n",
    "# path='/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'\n",
    "def create_data():\n",
    "       for i in range(len(train)):\n",
    "            arr=[]\n",
    "            for j in train.iloc[i]:\n",
    "                   arr.append(j)\n",
    "            img_array=cv2.imread(os.path.join(images,arr[0]),cv2.IMREAD_GRAYSCALE)\n",
    "            crop_image = img_array[arr[2]:arr[4],arr[1]:arr[3]]\n",
    "            new_img_array=cv2.resize(crop_image,(img_size,img_size))\n",
    "            data.append([new_img_array,arr[5]])\n",
    "create_data()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]\n",
    "plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl=LabelEncoder()\n",
    "y=lbl.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x).reshape(-1,50,50,1)\n",
    "x=tf.keras.utils.normalize(x,axis=1)\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "model=Sequential()\n",
    "model.add(Conv2D(100,(3,3),input_shape=x.shape[1:],activation='relu',strides=2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "model.fit(x,y,epochs=30,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=MTCNN()\n",
    "img=plt.imread(os.path.join(images,test_images[0]))\n",
    "face=detector.detect_faces(img)\n",
    "for face in face:\n",
    "        bounding_box=face['box']\n",
    "        x=cv2.rectangle(img,\n",
    "              (bounding_box[0], bounding_box[1]),\n",
    "              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "              (0,155,255),\n",
    "              10)\n",
    "        plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imread(os.path.join(images,test_images[3]))\n",
    "face=detector.detect_faces(img)\n",
    "for face in face:\n",
    "        bounding_box=face['box']\n",
    "        x=cv2.rectangle(img,\n",
    "              (bounding_box[0], bounding_box[1]),\n",
    "              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "              (0,155,255),\n",
    "              10)\n",
    "        plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=MTCNN()\n",
    "test_df=[]\n",
    "for image in test_images:\n",
    "    img=plt.imread(os.path.join(images,image))\n",
    "    faces=detector.detect_faces(img)\n",
    "    test=[]\n",
    "    for face in faces:\n",
    "        bounding_box=face['box']\n",
    "        test.append([image,bounding_box])\n",
    "    test_df.append(test)\n",
    "test=[]\n",
    "for i in test_df:\n",
    "    if len(i)>0:\n",
    "        if len(i)==1:\n",
    "            test.append(i[0])\n",
    "        else:\n",
    "            for j in i:\n",
    "                test.append(j)  \n",
    "sub=[]\n",
    "rest_image=[]\n",
    "for i in test:\n",
    "    sub.append(i[0])\n",
    "for image in test_images:\n",
    "    if image not in sub:\n",
    "        rest_image.append(image) \n",
    "detector=MTCNN()\n",
    "test_df_=[]\n",
    "for image in rest_image:\n",
    "    img=cv2.imread(os.path.join(images,image))\n",
    "    faces=detector.detect_faces(img)\n",
    "    test_=[]\n",
    "    for face in faces:\n",
    "        bounding_box=face['box']\n",
    "        test_.append([image,bounding_box])\n",
    "    test_df_.append(test_) \n",
    "for i in test_df_:\n",
    "    if len(i)>0:\n",
    "        if len(i)==1:\n",
    "            test.append(i[0])\n",
    "        else:\n",
    "            for j in i:\n",
    "                test.append(j)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative=[]\n",
    "for i in test:\n",
    "    for j in i[1]:\n",
    "        if j<0:\n",
    "            negative.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "def create_test_data():\n",
    "            for j in test:\n",
    "                if j not in negative:\n",
    "                    img=cv2.imread(os.path.join(images,j[0]),cv2.IMREAD_GRAYSCALE)\n",
    "                    img=img[j[1][1]:j[1][1]+j[1][3],j[1][0]:j[1][0]+j[1][2]]\n",
    "                    new_img=cv2.resize(img,(50,50))\n",
    "                    new_img=new_img.reshape(-1,50,50,1)\n",
    "                    predict=model.predict(new_img)\n",
    "                    test_data.append([j,predict])\n",
    "\n",
    "create_test_data()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=[]\n",
    "classname=[]\n",
    "for i,j in test_data:\n",
    "    classname.append(np.argmax(j))\n",
    "    image.append(i)\n",
    "df=pd.DataFrame(columns=['image','classname'])\n",
    "df['image']=image\n",
    "df['classname']=classname\n",
    "df['classname']=lbl.inverse_transform(df['classname'])\n",
    "image=[]\n",
    "x1=[]\n",
    "x2=[]\n",
    "y1=[]\n",
    "y2=[]\n",
    "for i in df['image']:\n",
    "    image.append(i[0])\n",
    "    x1.append(i[1][0])\n",
    "    x2.append(i[1][1])\n",
    "    y1.append(i[1][2])\n",
    "    y2.append(i[1][3])\n",
    "df['name']=image\n",
    "df['x1']=x1\n",
    "df['x2']=x2\n",
    "df['y1']=y1\n",
    "df['y2']=y2    \n",
    "df.drop(['image'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('name',axis=0,inplace=True,ascending=False)\n",
    "df.to_csv('example_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
