{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T21:16:03.377218Z",
     "start_time": "2020-11-11T21:15:59.800442Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline \n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T21:16:03.405985Z",
     "start_time": "2020-11-11T21:16:03.379301Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = !pwd\n",
    "NOTEBOOK_DIR = NOTEBOOK_DIR[0]\n",
    "ROOT_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "ANNOTATIONS_DIR = os.path.join(DATA_DIR, 'annotations')\n",
    "SUB_IMAGES_DIR = os.path.join(IMAGES_DIR, 'sub')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "MNM_MODEL_DIR = os.path.join(MODEL_DIR, 'keras_mask_or_no_mask_model')\n",
    "HC_MODEL_DIR = os.path.join(MODEL_DIR, 'mask_recog_ver2.h5')\n",
    "HC_DATA_DIR = os.path.join(DATA_DIR, 'haar_cascades')\n",
    "\n",
    "HC_FRONTAL_FACE_DIR = os.path.join(HC_DATA_DIR, \n",
    "                                   'haarcascade_frontalface_default.xml')\n",
    "HC_FRONTAL_FACE_ALT1_DIR = os.path.join(HC_DATA_DIR,\n",
    "                                     'haarcascade_frontalface_alt.xml')\n",
    "HC_FRONTAL_FACE_ALT2_DIR = os.path.join(HC_DATA_DIR,\n",
    "                                       'haarcascade_frontalface_alt2.xml')\n",
    "HC_PROFILE_FACE_DIR = os.path.join(HC_DATA_DIR,\n",
    "                                  'haarcascade_profileface.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T21:16:03.492336Z",
     "start_time": "2020-11-11T21:16:03.409844Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def array_to_image(a, fmt='jpeg'):\n",
    "    #Create binary stream object\n",
    "    f = BytesIO()\n",
    "\n",
    "    #Convert array to binary stream object\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "\n",
    "    return IPython.display.Image(data=f.getvalue())\n",
    "\n",
    "def get_frame(cap):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #flip image for natural viewing\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "frontal_face_cascade = cv2.CascadeClassifier(HC_FRONTAL_FACE_DIR)\n",
    "frontal_face_alt1 = cv2.CascadeClassifier(HC_FRONTAL_FACE_ALT1_DIR)\n",
    "frontal_face_alt2 = cv2.CascadeClassifier(HC_FRONTAL_FACE_ALT2_DIR)\n",
    "profile_face_cascade = cv2.CascadeClassifier(HC_PROFILE_FACE_DIR)\n",
    "cascades = [frontal_face_cascade, frontal_face_alt1, frontal_face_alt2, profile_face_cascade]\n",
    "\n",
    "def detect_faces(frame, neighbors=5, scale=1.1):\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.equalizeHist(frame_gray)\n",
    "    \n",
    "    frontal = frontal_face_cascade.detectMultiScale(frame_gray, scale, neighbors)\n",
    "#     frontalt1 = frontal_face_alt1.detectMultiScale(frame_gray, scale, neighbors)\n",
    "#     frontalt2 = frontal_face_alt2.detectMultiScale(frame_gray, scale, neighbors)\n",
    "    profile = profile_face_cascade.detectMultiScale(frame_gray, scale, neighbors)\n",
    "    \n",
    "    faces = {\n",
    "        'frontal': frontal,\n",
    "#         'frontal_alt1': frontalt1,\n",
    "#         'frontal_alt2': frontalt2,\n",
    "        'profile': profile\n",
    "    }\n",
    "    \n",
    "    return faces\n",
    "    \n",
    "def print_faces(faces):\n",
    "    print(\"Frontal (default):\")\n",
    "    for face in faces['frontal']:\n",
    "        print(face)\n",
    "    \n",
    "#     print(\"\\nFrontal (alt1):\")\n",
    "#     for face in faces['frontal_alt1']:\n",
    "#         print(face)\n",
    "        \n",
    "#     print(\"\\nFrontal (alt2):\")\n",
    "#     for face in faces['frontal_alt2']:\n",
    "#         print(face)\n",
    "    \n",
    "    print(\"\\nProfile:\")\n",
    "    for face in faces['profile']:\n",
    "        print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T21:16:03.539883Z",
     "start_time": "2020-11-11T21:16:03.494176Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['face_no_mask', 'face_with_mask'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'img_data/kaggle_training.csv'), index_col=False)\n",
    "train_df.rename(\n",
    "    columns={'x1': 'x', 'x2': 'y', 'y1': 'w', 'y2': 'h'},\n",
    "    inplace=True\n",
    ")\n",
    "train_df.sort_values('name', axis = 0, inplace = True)\n",
    "features = [\n",
    "    'face_with_mask', \n",
    "    'face_no_mask', \n",
    "]\n",
    "train_df = train_df[train_df['classname'].isin(features)]\n",
    "train_df['classname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T21:16:05.017010Z",
     "start_time": "2020-11-11T21:16:03.541487Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "detector = MTCNN()\n",
    "model = keras.models.load_model(MNM_MODEL_DIR)\n",
    "labeler = LabelEncoder()\n",
    "\n",
    "y = list(set(train_df['classname']))\n",
    "y = labeler.fit_transform(y)\n",
    "y = to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T21:15:59.809Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 241 248 ... 113 119 135]\n"
     ]
    }
   ],
   "source": [
    "CYAN = (0, 255, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "MAGENTA = (255, 0, 255)\n",
    "\n",
    "cap = cv2.VideoCapture('../../video_test_me.mov')\n",
    "rval, frame = cap.read()\n",
    "\n",
    "session_data = list()\n",
    "count = 1\n",
    "while cap.isOpened(): \n",
    "    #Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "#     frame = get_frame(cap)\n",
    "    \n",
    "    if frame is not None:\n",
    "        im = np.asarray(bytearray(frame), dtype=\"uint8\")\n",
    "        frame = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)\n",
    "#         frame = cv2.cvtColor(frame, cv2.IMREAD_COLOR)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         image = array_to_image(frame)\n",
    "\n",
    "        #Use MTCNN to detect faces\n",
    "        faces = detector.detect_faces(rgb)\n",
    "        \n",
    "        # Use Haar Cascade to detect faces\n",
    "#         faces = detect_faces(frame)\n",
    "#         faces = frontal_face_cascade.detectMultiScale(gray,\n",
    "#                                              scaleFactor=1.1,\n",
    "#                                              minNeighbors=5,\n",
    "#                                              minSize=(60, 60),\n",
    "#                                              flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "#         print_faces(faces)\n",
    "        \n",
    "        if faces != []:\n",
    "            \n",
    "            data = list()\n",
    "            results = list()\n",
    "            frame_df = pd.DataFrame()\n",
    "            \n",
    "#             print(faces)\n",
    "            for face in faces:\n",
    "#                 data.append([count, face['box']])\n",
    "                bounding_box = face['box']       # for use with MTCNN\n",
    "                keypoints = face['keypoints']    # for use with MTCNN\n",
    "#                 bounding_box = face\n",
    "                x, y, w, h = bounding_box        # for use with MTCNN\n",
    "                img = gray[y:y+h,x:x+w]\n",
    "\n",
    "                try:\n",
    "                    new_img = cv2.resize(img, (50, 50))\n",
    "                    new_img = new_img.reshape(-1, 50, 50, 1)\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                prediction = model.predict(new_img)\n",
    "#                 print(prediction)\n",
    "#                 print(\"PREDICTION: {}\".format(labeler.inverse_transform(prediction)))\n",
    "                data.append([count, bounding_box, prediction])\n",
    "    \n",
    "                cv2.circle(rgb,(keypoints['left_eye']), 2, CYAN, 2)\n",
    "                cv2.circle(rgb,(keypoints['right_eye']), 2, CYAN, 2)\n",
    "                cv2.circle(rgb,(keypoints['nose']), 2, CYAN, 2)\n",
    "                cv2.circle(rgb,(keypoints['mouth_left']), 2, CYAN, 2)\n",
    "                cv2.circle(rgb,(keypoints['mouth_right']), 2, CYAN, 2)\n",
    "            \n",
    "#             for face in faces['profile']:\n",
    "# #                 data.append([count, face['box']])\n",
    "# #                 bounding_box = face['box']       # for use with MTCNN\n",
    "# #                 keypoints = face['keypoints']    # for use with MTCNN\n",
    "#                 bounding_box = face\n",
    "#                 x, y, w, h = bounding_box        # for use with MTCNN\n",
    "#                 img = gray[y:y+h,x:x+w]\n",
    "\n",
    "#                 try:\n",
    "#                     new_img = cv2.resize(img, (50, 50))\n",
    "#                     new_img = new_img.reshape(-1, 50, 50, 1)\n",
    "#                 except Exception as e:\n",
    "#                     print(str(e))\n",
    "#                 prediction = model.predict(new_img)\n",
    "# #                 print(prediction)\n",
    "# #                 print(\"PREDICTION: {}\".format(labeler.inverse_transform(prediction)))\n",
    "#                 data.append([count, bounding_box, prediction])\n",
    "    \n",
    "#             for face in faces['frontal']:\n",
    "# #                 data.append([count, face['box']])\n",
    "# #                 bounding_box = face['box']       # for use with MTCNN\n",
    "# #                 keypoints = face['keypoints']    # for use with MTCNN\n",
    "#                 bounding_box = face\n",
    "#                 x, y, w, h = bounding_box        # for use with MTCNN\n",
    "#                 img = gray[y:y+h,x:x+w]\n",
    "\n",
    "#                 try:\n",
    "#                     new_img = cv2.resize(img, (50, 50))\n",
    "#                     new_img = new_img.reshape(-1, 50, 50, 1)\n",
    "#                 except Exception as e:\n",
    "#                     print(str(e))\n",
    "#                 prediction = model.predict(new_img)\n",
    "# #                 print(prediction)\n",
    "# #                 print(\"PREDICTION: {}\".format(labeler.inverse_transform(prediction)))\n",
    "#                 data.append([count, bounding_box, prediction])\n",
    "                \n",
    "            print(data)\n",
    "            results += [i for i in data if len(i) == 1]\n",
    "            results += [[j for j in i] for i in data if len(i) > 1]\n",
    "\n",
    "            print(results)\n",
    "            image = []\n",
    "            classname = []\n",
    "            for k, i, j in results:\n",
    "                cn = np.argmax(j)\n",
    "                classname.append(cn)# if cn < 2 else 0)\n",
    "                image.append(i)\n",
    "            \n",
    "            \n",
    "            print(\"FRAME NO.: {}\\nCLASSNAME ARGMAX: {}\\nINVERSE TRANSFORM: {}\\n\".format(\n",
    "                count, classname, labeler.inverse_transform(classname)\n",
    "            ))\n",
    "            frame_df['image'] = image\n",
    "            frame_df['classname'] = classname\n",
    "            frame_df['classname'] = labeler.inverse_transform(frame_df['classname'])\n",
    "            print(frame_df)\n",
    "\n",
    "\n",
    "            for i in range(len(frame_df)):\n",
    "                x, y, w, h = frame_df.iloc[i]['image']\n",
    "                cname = str(frame_df.iloc[i]['classname'])\n",
    "               \n",
    "                if cname == 'face_with_mask':\n",
    "                    label = \"Mask\"\n",
    "                else:\n",
    "                    label = \"No Mask\"\n",
    "                color = (0, 255, 0) if label == 'Mask' else (255,0,0)\n",
    "                cv2.putText(rgb, label, (x, y- 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1)\n",
    "                        \n",
    "                cv2.rectangle(rgb, (x, y), (x + w, y + h),color, 3)\n",
    "\n",
    "            session_data.append(results)\n",
    "\n",
    "\n",
    "        #display resulting frame\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('frame', rgb)\n",
    "#         plt.imshow(frame, interpolation = 'bicubic')\n",
    "#         print(frame.shape)\n",
    "        \n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break\n",
    "#When everything's done, release capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# exception at frame 16-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T21:15:59.811Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-11T21:15:59.812Z"
    }
   },
   "outputs": [],
   "source": [
    "session_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}