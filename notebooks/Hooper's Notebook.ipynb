{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is intended for grading purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will install all the modules and packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that these tensorflow packages only work on Python versions < 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline \n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make sure all the directories we might need are ready to be called on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = !pwd\n",
    "NOTEBOOK_DIR = NOTEBOOK_DIR[0]\n",
    "ROOT_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "ANNOTATIONS_DIR = os.path.join(DATA_DIR, 'annotations')\n",
    "SUB_IMAGES_DIR = os.path.join(IMAGES_DIR, 'sub')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "MNM_MODEL_DIR = os.path.join(MODEL_DIR, 'keras_mask_or_no_mask_model')\n",
    "CINC_WORN_MASKS_DIR = os.path.join(MODEL_DIR, 'keras_8_feature_incorrect_mask_sequential_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['face_no_mask', 'face_with_mask'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'img_data/kaggle_training.csv'), index_col=False)\n",
    "train_df.rename(\n",
    "    columns={'x1': 'x', 'x2': 'y', 'y1': 'w', 'y2': 'h'},\n",
    "    inplace=True\n",
    ")\n",
    "train_df.sort_values('name', axis = 0, inplace = True)\n",
    "features = [\n",
    "    'face_with_mask', \n",
    "    'face_no_mask', \n",
    "]\n",
    "train_df = train_df[train_df['classname'].isin(features)]\n",
    "train_df['classname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = keras.models.load_model(MNM_MODEL_DIR)\n",
    "labeler = LabelEncoder()\n",
    "detector = MTCNN()\n",
    "\n",
    "y = list(set(train_df['classname']))\n",
    "\n",
    "y = labeler.fit_transform(y)\n",
    "\n",
    "y = to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see our failures in LIVE-TIME :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70, [577, 139, 260, 323], array([[0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [2.0197724e-13, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00],\n",
      "       [1.6494603e-34, 1.0000000e+00],\n",
      "       [1.0000000e+00, 0.0000000e+00]], dtype=float32)]]\n",
      "FRAME NO.: 70\n",
      "CLASSNAME ARGMAX: [1]\n",
      "INVERSE TRANSFORM: ['face_with_mask']\n",
      "\n",
      "                  image       classname\n",
      "0  [577, 139, 260, 323]  face_with_mask\n"
     ]
    }
   ],
   "source": [
    "CYAN = (0, 255, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "MAGENTA = (255, 0, 255)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "rval, frame = cap.read()\n",
    "\n",
    "session_data = list()\n",
    "count = 1\n",
    "while cap.isOpened(): \n",
    "    #Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "#     frame = get_frame(cap)\n",
    "\n",
    "    if frame is not None:\n",
    "        grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = array_to_image(frame)\n",
    "\n",
    "        #Use MTCNN to detect faces\n",
    "        faces = detector.detect_faces(grayFrame)\n",
    "        if faces != []:\n",
    "            \n",
    "            data = list()\n",
    "            results = list()\n",
    "            frame_df = pd.DataFrame()\n",
    "            for face in faces:\n",
    "#                 data.append([count, face['box']])\n",
    "                bounding_box = face['box']\n",
    "                keypoints = face['keypoints']\n",
    "                x, y, w, h = bounding_box\n",
    "                img = frame[y:y+h,x:x+w]\n",
    "\n",
    "                try:\n",
    "                    new_img = cv2.resize(img, (150, 150))\n",
    "                    new_img = new_img.reshape(-1, 50, 50, 1)\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                prediction = model.predict(new_img)\n",
    "#                 print(prediction)\n",
    "#                 print(\"PREDICTION: {}\".format(labeler.inverse_transform(prediction)))\n",
    "                data.append([count, bounding_box, prediction])\n",
    "                \n",
    "                cv2.circle(frame,(keypoints['left_eye']), 2, CYAN, 2)\n",
    "                cv2.circle(frame,(keypoints['right_eye']), 2, CYAN, 2)\n",
    "                cv2.circle(frame,(keypoints['nose']), 2, CYAN, 2)\n",
    "                cv2.circle(frame,(keypoints['mouth_left']), 2, CYAN, 2)\n",
    "                cv2.circle(frame,(keypoints['mouth_right']), 2, CYAN, 2)\n",
    "                \n",
    "            print(data)\n",
    "            results += [i for i in data if len(i) == 1]\n",
    "            results += [[j for j in i] for i in data if len(i) > 1]\n",
    "\n",
    "#             print(results)\n",
    "            image = []\n",
    "            classname = []\n",
    "            for k, i, j in results:\n",
    "                cn = np.argmax(j)\n",
    "                classname.append(cn if cn < 2 else 0)\n",
    "                image.append(i)\n",
    "            \n",
    "            \n",
    "            print(\"FRAME NO.: {}\\nCLASSNAME ARGMAX: {}\\nINVERSE TRANSFORM: {}\\n\".format(\n",
    "                count, classname, labeler.inverse_transform(classname)\n",
    "            ))\n",
    "            frame_df['image'] = image\n",
    "            frame_df['classname'] = classname\n",
    "            frame_df['classname'] = labeler.inverse_transform(frame_df['classname'])\n",
    "            print(frame_df)\n",
    "\n",
    "\n",
    "            for i in range(len(frame_df)):\n",
    "                x, y, w, h = frame_df.iloc[i]['image']\n",
    "                cname = str(frame_df.iloc[i]['classname'])\n",
    "               \n",
    "                if cname == 'face_with_mask':\n",
    "                    label = \"Mask\"\n",
    "                else:\n",
    "                    label = \"No Mask\"\n",
    "                color = GREEN if label == 'Mask' else MAGENTA\n",
    "                cv2.putText(frame, label, (x, y- 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 4)\n",
    "                        \n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
    "\n",
    "            session_data.append(results)\n",
    "\n",
    "\n",
    "        #display resulting frame\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('frame', frame)\n",
    "#         plt.imshow(frame, interpolation = 'bicubic')\n",
    "#         print(frame.shape)\n",
    "        \n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break\n",
    "#When everything's done, release capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
