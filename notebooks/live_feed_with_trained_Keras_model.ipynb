{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:03:51.465174Z",
     "start_time": "2020-11-10T20:03:51.462931Z"
    }
   },
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "#\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:03:51.469322Z",
     "start_time": "2020-11-10T20:03:51.467309Z"
    }
   },
   "outputs": [],
   "source": [
    "# jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:03:56.425533Z",
     "start_time": "2020-11-10T20:03:51.471521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential        # keras is only compatible with python 3.6 or lower\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:03:56.456147Z",
     "start_time": "2020-11-10T20:03:56.427531Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = !pwd\n",
    "NOTEBOOK_DIR = NOTEBOOK_DIR[0]\n",
    "ROOT_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "ANNOTATIONS_DIR = os.path.join(DATA_DIR, 'annotations')\n",
    "SUB_IMAGES_DIR = os.path.join(IMAGES_DIR, 'sub')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "MNM_MODEL_DIR = os.path.join(MODEL_DIR, 'keras_mask_or_no_mask_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:03:56.584505Z",
     "start_time": "2020-11-10T20:03:56.458617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brtonnies/ArtificialIntelligence/face-mask-detection/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:03:56.594871Z",
     "start_time": "2020-11-10T20:03:56.589081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brtonnies/ArtificialIntelligence/face-mask-detection/models/keras_mask_or_no_mask_model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNM_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:16:42.506761Z",
     "start_time": "2020-11-10T20:16:36.936947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[{'box': [2909, 195, 20, 25], 'confidence': 0.9998680353164673, 'keypoints': {'left_eye': (2915, 204), 'right_eye': (2925, 204), 'nose': (2920, 210), 'mouth_left': (2915, 213), 'mouth_right': (2924, 214)}}, {'box': [557, 62, 70, 87], 'confidence': 0.9998065829277039, 'keypoints': {'left_eye': (578, 93), 'right_eye': (612, 94), 'nose': (596, 113), 'mouth_left': (577, 124), 'mouth_right': (610, 125)}}, {'box': [868, 64, 49, 64], 'confidence': 0.7396073341369629, 'keypoints': {'left_eye': (879, 89), 'right_eye': (901, 88), 'nose': (887, 101), 'mouth_left': (882, 116), 'mouth_right': (899, 116)}}]\n",
      "(1, 50, 50, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'color' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-79fe458718ec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;31m#                     cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m         \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrectangle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mcolor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[0;31m# Display the resulting frame\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'color' is not defined"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "# import numpy as np\n",
    " \n",
    "# # cascPath = os.path.dirname(\n",
    "# #     cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# # faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "# model = load_model(MNM_MODEL_DIR)\n",
    "# detector = MTCNN()\n",
    "# video_capture = cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#     # Capture frame-by-frame\n",
    "  \n",
    "#     ret, frame = video_capture.read()\n",
    "#     result = detector.detect_faces(frame)\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# #     faces = faceCascade.detectMultiScale(gray,\n",
    "# #                                          scaleFactor=1.1,\n",
    "# #                                          minNeighbors=5,\n",
    "# #                                          minSize=(60, 60),\n",
    "# #                                          flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "#     faces = detector.detect_faces(frame)\n",
    "#     faces_list=[]\n",
    "#     preds=[]\n",
    "    \n",
    "#     contours, hierarchy = cv2.findContours(frame, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "#     faces_list.append(coun)\n",
    "#     if len(faces_list)>0:\n",
    "#         preds = model.predict(faces_list)\n",
    "#     for pred in preds:\n",
    "#         (mask, withoutMask) = pred\n",
    "#     label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "#     color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "#     label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "#     cv2.putText(frame, label, (x, y- 10),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    " \n",
    "#     cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
    "#         # Display the resulting frame\n",
    "#     cv2.imshow('Video', frame)\n",
    "#     if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "#         break\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "\n",
    " \n",
    "# cascPath = os.path.dirname(\n",
    "#     cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "model = load_model(MNM_MODEL_DIR)\n",
    "detector = MTCNN()\n",
    " \n",
    "video_capture = cv2.VideoCapture(\"/Users/brtonnies/Desktop/Screen Recording 2020-11-04 at 5.55.09 PM.mov\")\n",
    "print(video_capture.isOpened())\n",
    "ret, frame = video_capture.read()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = faceCascade.detectMultiScale(gray,\n",
    "#                                          scaleFactor=1.1,\n",
    "#                                          minNeighbors=5,\n",
    "#                                          minSize=(60, 60),\n",
    "#                                          flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    faces = detector.detect_faces(frame)\n",
    "    print(faces)\n",
    "    faces_list=[]\n",
    "    preds=[]\n",
    "    for (x, y, w, h) in [face['box'] for face in faces]:\n",
    "        face_frame = frame[y:y+h,x:x+w]\n",
    "        face_frame = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
    "        face_frame = np.asarray(cv2.resize(face_frame, (50,50)))\n",
    "        face_frame = img_to_array(face_frame)\n",
    "        face_frame = np.expand_dims(face_frame, axis=0)\n",
    "        face_frame =  preprocess_input(face_frame)\n",
    "        print(face_frame.shape)\n",
    "#         preds.append(model.predict(face_frame))\n",
    "        faces_list.append(face_frame)\n",
    "#         if len(faces_list)>0:\n",
    "#             preds = model.predict(faces_list)\n",
    "#         for pred in preds:\n",
    "#             (mask, withoutMask) = pred\n",
    "#         label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "#         color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "#         label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "#         cv2.putText(frame, label, (x, y- 10),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    " \n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "         break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}