{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-68dcfb427789>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-68dcfb427789>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jupyter kernelspec list\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential        # keras is only compatible with python 3.6 or lower\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = !pwd\n",
    "NOTEBOOK_DIR = NOTEBOOK_DIR[0]\n",
    "ROOT_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "ANNOTATIONS_DIR = os.path.join(DATA_DIR, 'annotations')\n",
    "SUB_IMAGES_DIR = os.path.join(IMAGES_DIR, 'sub')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "MNM_MODEL_DIR = os.path.join(MODEL_DIR, 'keras_mask_or_no_mask_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kellymcgaw/Desktop/AI_class/face-mask-detection/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-481a6d1e6c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mbounding_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'box'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mkeypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keypoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    " \n",
    "# cascPath = os.path.dirname(\n",
    "#     cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "model = load_model(MNM_MODEL_DIR)\n",
    "detector = MTCNN()\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = faceCascade.detectMultiScale(gray,\n",
    "#                                          scaleFactor=1.1,\n",
    "#                                          minNeighbors=5,\n",
    "#                                          minSize=(60, 60),\n",
    "#                                          flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    faces = detector.detect_faces(frame)\n",
    "    faces_list=[]\n",
    "    preds=[]\n",
    "    faces = detector.detect_faces(frame)\n",
    "    if faces != []:\n",
    "        data = list()\n",
    "        results = list()\n",
    "        for face in faces:\n",
    "            bounding_box = face['box']\n",
    "            keypoints = face['keypoints']\n",
    "            data.append([count, bounding_box])\n",
    "                \n",
    "            x, y, w, h = bounding_box\n",
    "            img = frame[y:y+h,x:x+w]\n",
    "            if img != []:\n",
    "                new_img = cv2.resize(img,(50,50))\n",
    "                new_img = new_img.reshape(-1,50,50,1)\n",
    "                prediction = model.predict(new_img)\n",
    "                print(\"PREDICTION: {}\".format(prediction))\n",
    "                results.append([count, bounding_box, prediction])\n",
    "                cv2.rectangle(frame,\n",
    "                              (x, y),\n",
    "                              (x+w, y + h),\n",
    "                              (0,155,255),\n",
    "                              2)\n",
    "\n",
    "                cv2.circle(frame,(keypoints['left_eye']), 2, (0,155,255), 2)\n",
    "                cv2.circle(frame,(keypoints['right_eye']), 2, (0,155,255), 2)\n",
    "                cv2.circle(frame,(keypoints['nose']), 2, (0,155,255), 2)\n",
    "                cv2.circle(frame,(keypoints['mouth_left']), 2, (0,155,255), 2)\n",
    "                cv2.circle(frame,(keypoints['mouth_right']), 2, (0,155,255), 2)\n",
    "        # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
