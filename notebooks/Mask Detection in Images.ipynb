{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Face Masks in Images (Keras)\n",
    "\n",
    "#### Basic steps:\n",
    "1. Given images, detect facial regions and features (find faces)\n",
    "2. Create train/test data with facial regions as inputs\n",
    "3. Using supervised model with training images, predict whether there is a mask in the facial region\n",
    "\n",
    "#### Environment Setup\n",
    "\n",
    "1. Use/create a new [Anaconda](https://www.anaconda.com/products/individual) environment with Python 3.6 (not 3.7 or 3.8), keras, and tensorflow:\n",
    "``` sh\n",
    "$ conda create -n <your_env_name> python=3.6 anaconda tensorflow keras\n",
    "```\n",
    "2. Install dependencies:\n",
    "``` sh\n",
    "$ conda install -c anaconda xlrd xlwt scikit-learn seaborn\n",
    "$ conda install mtcnn ipyparallel validators\n",
    "$ pip install python-opencv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:07.455877Z",
     "start_time": "2020-11-10T21:56:07.373916Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# i hate this, but the notebook won't recognize our custom modules w/o it\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import lib\n",
    "from lib import utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential        # keras is only compatible with python 3.6 or lower\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Grab/Process Image Data\n",
    "\n",
    "1. For our purposes as of the time of writing this, there should be a prepared dataframe for images not in our training set located in the data directory: `data/img_data/unclassified.csv`\n",
    "  + The prepared data frame is made up of rows containing the image filename, the coordinates of one face's bounding box, and an empty column 'classname' where the classification results would otherwise be.\n",
    "2. Currently, we're using the training set from Kaggle's medical masks dataset.\n",
    "  + This data is similarly prepared already, but it has it's classname column filled (mask/no mask/colorful mask)\n",
    "  + Ideally, we could get some additional images for the training set containing masks that are not strictly 'medical' looking (anything that effectively covers the nose and mouth: bandanas, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:09.328676Z",
     "start_time": "2020-11-10T21:56:09.283366Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jpg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GITHUB IMAGE LOCATIONS/HELPERS (maybe we can save some local space)\n",
    "IMAGES_DIR_GIT = \"https://github.com/brtonnies/face-mask-detection/blob/main/data/images\"\n",
    "CMFD_DIR_GIT = \"https://github.com/brtonnies/face-mask-detection/blob/main/data/images/CMFD/images\"\n",
    "IMFD_DIR_GIT = \"https://github.com/brtonnies/face-mask-detection/blob/main/data/images/IMFD/images\"\n",
    "\n",
    "# define directory paths for easier navigation\n",
    "NOTEBOOK_DIR = !pwd\n",
    "NOTEBOOK_DIR = NOTEBOOK_DIR[0]\n",
    "ROOT_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "ANNOTATIONS_DIR = os.path.join(DATA_DIR, 'annotations')\n",
    "SUB_IMAGES_DIR = os.path.join(IMAGES_DIR, 'sub')\n",
    "\n",
    "'0001.jpg'.split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:11.199376Z",
     "start_time": "2020-11-10T21:56:11.196403Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-1c9e2351caca>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-1c9e2351caca>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://github.com/brtonnies/face-mask-detection/blob/main/data/images/0001.jpg?raw=true\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://github.com/brtonnies/face-mask-detection/blob/main/data/images/0001.jpg?raw=true\n",
    "name = '0001.jpg'\n",
    "options = {\n",
    "    'lib': 'plt',\n",
    "    'format': name.split(\".\")[-1]\n",
    "}\n",
    "\n",
    "img = utils.get_kaggle_img(name, options)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:12.812888Z",
     "start_time": "2020-11-10T21:56:12.738706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13381</th>\n",
       "      <td>1801.jpg</td>\n",
       "      <td>451</td>\n",
       "      <td>186</td>\n",
       "      <td>895</td>\n",
       "      <td>697</td>\n",
       "      <td>face_no_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>1802.jpg</td>\n",
       "      <td>160</td>\n",
       "      <td>151</td>\n",
       "      <td>268</td>\n",
       "      <td>265</td>\n",
       "      <td>mask_surgical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>1802.jpg</td>\n",
       "      <td>110</td>\n",
       "      <td>71</td>\n",
       "      <td>273</td>\n",
       "      <td>272</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>1803.jpg</td>\n",
       "      <td>147</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>320</td>\n",
       "      <td>mask_surgical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>1803.jpg</td>\n",
       "      <td>126</td>\n",
       "      <td>75</td>\n",
       "      <td>303</td>\n",
       "      <td>333</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13555</th>\n",
       "      <td>6433.png</td>\n",
       "      <td>669</td>\n",
       "      <td>205</td>\n",
       "      <td>774</td>\n",
       "      <td>282</td>\n",
       "      <td>mask_surgical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>6434.jpg</td>\n",
       "      <td>315</td>\n",
       "      <td>82</td>\n",
       "      <td>775</td>\n",
       "      <td>783</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9507</th>\n",
       "      <td>6434.jpg</td>\n",
       "      <td>343</td>\n",
       "      <td>448</td>\n",
       "      <td>756</td>\n",
       "      <td>774</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>6435.jpg</td>\n",
       "      <td>198</td>\n",
       "      <td>86</td>\n",
       "      <td>292</td>\n",
       "      <td>149</td>\n",
       "      <td>mask_surgical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>6435.jpg</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>148</td>\n",
       "      <td>face_with_mask_incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15412 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name    x    y    w    h                 classname\n",
       "13381  1801.jpg  451  186  895  697              face_no_mask\n",
       "3464   1802.jpg  160  151  268  265             mask_surgical\n",
       "3463   1802.jpg  110   71  273  272            face_with_mask\n",
       "14836  1803.jpg  147  200  288  320             mask_surgical\n",
       "14835  1803.jpg  126   75  303  333            face_with_mask\n",
       "...         ...  ...  ...  ...  ...                       ...\n",
       "13555  6433.png  669  205  774  282             mask_surgical\n",
       "9508   6434.jpg  315   82  775  783            face_with_mask\n",
       "9507   6434.jpg  343  448  756  774             mask_colorful\n",
       "9434   6435.jpg  198   86  292  149             mask_surgical\n",
       "9433   6435.jpg  140    1  293  148  face_with_mask_incorrect\n",
       "\n",
       "[15412 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Kaggle training data\n",
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "df_train.rename(\n",
    "    columns={'x1': 'x', 'x2': 'y', 'y1': 'w', 'y2': 'h'},\n",
    "    inplace=True\n",
    ")\n",
    "df_train.sort_values('name', axis = 0, inplace = True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:14.399251Z",
     "start_time": "2020-11-10T21:56:14.394785Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load testing data\n",
    "if os.path.exists(os.path.join(DATA_DIR, 'img_data/not_classified.csv')):\n",
    "\n",
    "    df_test = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, 'img_data/not_classified.csv'),\n",
    "        index_col=0\n",
    "    )\n",
    "    df_test.rename(\n",
    "        columns={'x1': 'x', 'x2': 'y', 'y1': 'w', 'y2': 'h'},\n",
    "        inplace=True\n",
    "    )\n",
    "    df_test.sort_values('name', axis = 0, inplace = True)\n",
    "else:\n",
    "    df_test = None\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:16.221423Z",
     "start_time": "2020-11-10T21:56:15.874937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['face_no_mask', 'mask_surgical', 'face_with_mask', 'hat',\n",
       "       'eyeglasses', 'face_other_covering', 'face_with_mask_incorrect',\n",
       "       'mask_colorful', 'sunglasses', 'helmet', 'scarf_bandana',\n",
       "       'hair_net', 'face_shield', 'goggles', 'hijab_niqab', 'turban',\n",
       "       'balaclava_ski_mask', 'gas_mask', 'hood', 'other'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = df_train['classname'].unique()\n",
    "_classes = np.insert(classes, 0, \"background\", axis=0)        # adding a background class for Faster R-CNN\n",
    "class_to_int = {_classes[i] : i for i in range(len(_classes))}\n",
    "int_to_class = {i : _classes[i] for i in range(len(_classes))}\n",
    "\n",
    "# specify which classnames we want to look at\n",
    "options = [\n",
    "    'face_with_mask', \n",
    "    'face_no_mask', \n",
    "    # 'mask_colorful',\n",
    "    # 'face_with_mask_incorrect',\n",
    "]\n",
    "\n",
    "### Visualizing Class Distribution\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Class Distribution', fontsize= 20)\n",
    "\n",
    "sns.countplot(x = \"classname\", data = df_train[df_train[\"classname\"].isin(options)])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:56:17.744719Z",
     "start_time": "2020-11-10T21:56:17.736178Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kellymcgaw/opt/anaconda3/envs/mm/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train = df_train[df_train['classname'].isin(options)]\n",
    "train.sort_values('name', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Up Next:\n",
    "\n",
    "1. We'll need to be able to look at each facial region within an image\n",
    "2. We'll also need to keep the data somewhere\n",
    "3. We also need to define and train a keras model before we can make any predictions \n",
    "\n",
    "## We know where our faces are... let's get our training data ready for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T21:57:29.629820Z",
     "start_time": "2020-11-10T21:56:30.096077Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1801.jpg 451 186 895 697 face_no_mask\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://github.com/brtonnies/face-mask-detection/blob/main/data/images/1801.jpg?raw=true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-caeadf07c619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGES_DIR_GIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}?raw=true\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     og_img = cv2.imread(os.path.join(IMAGES_DIR_GIT, \"{}?raw=true\".format(name)), cv2.IMREAD_GRAYSCALE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mog_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mm/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mm/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1462\u001b[0m             raise ValueError('Only know how to handle PNG; with Pillow '\n\u001b[1;32m   1463\u001b[0m                              'installed, Matplotlib can handle more images')\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mm/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/brtonnies/face-mask-detection/blob/main/data/images/1801.jpg?raw=true'"
     ]
    }
   ],
   "source": [
    "# train_images = df_train['name'].unique()\n",
    "data = list()\n",
    "# for image in train_images:\n",
    "for i in range(len(train)):\n",
    "    # name, x, y, w, h, classname = list(df_train[df_train['name'] == image].values[0])\n",
    "    name, x, y, w, h, classname = list(train.iloc[i])\n",
    "    print(name, x, y, w, h, classname)\n",
    "    imgs = plt.imread(os.path.join(IMAGES_DIR_GIT, \"{}?raw=true\".format(name)), format='jpg')\n",
    "#     og_img = cv2.imread(os.path.join(IMAGES_DIR_GIT, \"{}?raw=true\".format(name)), cv2.IMREAD_GRAYSCALE)\n",
    "    og_img = cv2.imread(imgs, cv2.IMREAD_GRAYSCALE)\n",
    "    cv2.imshow('image', og_img)\n",
    "    cropped = og_img[y:h, x:w]\n",
    "    if len(cropped) > 0:\n",
    "        new_img = cv2.resize(cropped, (50, 50)) # resize img to 50x50\n",
    "        data.append([new_img, classname])\n",
    "    \n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T03:22:07.513275Z",
     "start_time": "2020-11-10T03:22:07.214688Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dc75636bf327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plt.imshow(data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## A Few More Steps:\n",
    "1. Split training data into features and labels\n",
    "2. Convert labels to categorical values and reshape features\n",
    "3. Define/train a model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T03:22:07.523615Z",
     "start_time": "2020-11-10T03:22:07.515453Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into labels/features\n",
    "x=[]\n",
    "y=[]\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "\n",
    "# convert labels to categorical values\n",
    "labeler = LabelEncoder()\n",
    "y = labeler.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T03:22:07.737556Z",
     "start_time": "2020-11-10T03:22:07.526086Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8bb94078537c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mm/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mm/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2619\u001b[0m     \"\"\"\n\u001b[1;32m   2620\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2621\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mm/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# reshape features\n",
    "x = np.array(x).reshape(-1, 50, 50, 1)\n",
    "x = tf.keras.utils.normalize(x, axis=1)\n",
    "y = to_categorical(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Creation/Fitting\n",
    "\n",
    "1. Keras models can be created, compiled, trained, and then *saved* to a file and/or loaded from one.\n",
    "2. If there isn't a model file available, we have to create it.\n",
    "  + This takes awhile, so if there is an already trained/fit model, we're gonna use it\n",
    "\n",
    "### Model Choice: Keras Sequential Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T03:38:53.422875Z",
     "start_time": "2020-11-10T03:22:07.739832Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"../models/keras_sequential_model\"\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "if os.path.exists(model_path):\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "else:\n",
    "    batch_size = 5\n",
    "    epochs = 30\n",
    "    learning_rate = 1e-3\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(100, (3, 3), input_shape=x.shape[1:], activation='relu', strides=2))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x, y, epochs=epochs, batch_size=batch_size)\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T03:38:53.429676Z",
     "start_time": "2020-11-10T03:38:53.424731Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_faces(img):\n",
    "    detector = MTCNN()\n",
    "    image = plt.imread(os.path.join(IMAGES_DIR, img))\n",
    "    return detector.detect_faces(image)\n",
    "\n",
    "def face_bounds(face):\n",
    "    return face['box']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Let's Predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T21:12:17.681231Z",
     "start_time": "2020-10-30T21:12:17.385Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "batch_size = 5\n",
    "epochs = 30\n",
    "learning_rate = 1e-3\n",
    "epsilon = 1e-5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(100, (3, 3), input_shape=x.shape[1:], activation='relu', strides=2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=epochs, batch_size=batch_size)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
